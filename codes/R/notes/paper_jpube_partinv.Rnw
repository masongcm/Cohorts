
<<MAIN,cache=FALSE,echo=FALSE,results='hide',message=FALSE,warning=FALSE>>=
rm(list=ls())         # Clear all objects from memory 
  opts_chunk$set(concordance=FALSE,
                 echo=FALSE,
                 tidy=FALSE,
                 autodep=TRUE,
                 cache=T, # REPLACE LATER
                 message=FALSE, 
                 warning=FALSE,
                 size='scriptsize',
                 results='hide',
                 comment=NA, 
                 fig.width=4,
                 fig.height=4, 
                 out.width='\\textwidth',
                 fig.show='hold',
                 tikzDefaultEngine='pdftex',
                 tikzDocumentDeclaration = "\\documentclass[10pt]{article}",
                 tikzMetricPackages = c("\\usepackage[utf8]{inputenc}","\\usepackage[T1]{fontenc}", "\\usetikzlibrary{calc}", "\\usepackage{amssymb}")
                 )


@


<<READ, cache=FALSE >>=
library(here)
read_chunk(here("codes/R/1_load.R"))
read_chunk(here("codes/R/2_efa.R"))
read_chunk(here("codes/R/3_inv_main.R"))
read_chunk(here("codes/R/3_inv_part.R"))
read_chunk(here("codes/R/3_inv_aux.R"))
read_chunk(here("codes/R/3_inv_fit.R"))
read_chunk(here("codes/R/4_scores.R"))
read_chunk(here("codes/R/4_scores_aux.R"))
read_chunk(here("codes/R/5_graphs.R"))
read_chunk(here("codes/R/6_selectvars.R"))
read_chunk(here("codes/R/8_regs_dep.R"))
read_chunk(here("codes/R/8_regs_outc.R"))
read_chunk(here("codes/R/9_gelbfig.R"))
read_chunk(here("codes/R/getpars.R"))

@

<<PREAMBLE >>=
@

<<LOAD_DATA>>=
@

<<FUN_GETPARS>>=
# load function that gets parameters
@

<<MEANTABLE>>=
# make table with means
@

<<MEANTABLE_PRINT>>=
# function to print mean table
printmeantab <- function(tab) {
  print(xtable(tab,
               align="L{0cm}C{.04\\textwidth}C{.05\\textwidth}C{.05\\textwidth}L{.4\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}L{.4\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}",
               digits = 1
  ), 
  size="\\small",
  include.rownames=F,
  include.colnames=F,
  booktabs = T,
  add.to.row = list(pos = c(list(0)),
                    command = c(
                      # header
                      paste(" & & &
                            \\multicolumn{4}{c}{\\textbf{BCS}} &
                            \\multicolumn{4}{c}{\\textbf{MCS}} \\\\ \\cmidrule(lr){4-7} \\cmidrule(lr){8-11} 
                            Item & Factor & Num. Categ. &
                            Wording & Cert. Appl. (\\%) & Smtm. Appl. (\\%) & Appl. (\\%) &
                            Wording & Cert. True (\\%) & Smwt. True (\\%) & True (\\%) \\\\ \\midrule
                            "
                            , sep="")
                    )),
  sanitize.text.function = function(x){x},
  sanitize.rownames.function = function(x){""}, # to not print row numbers
  tabular.environment = "tabular", width = ".8\\textwidth",
  floating = FALSE
  )
}

@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<FA_INV_MAIN>>=
# main models only
@

<<FA_INV_PART>>=
# partial invariance (many models)
@

<<FA_FIT>>=
# assemble fit indices into matrices
@

<<FA_SCORES_MAIN>>=
# produce scores for main model
@

<<FA_SCORES_BIND>>=
# bind scores with data
@

<<FA_SCORES_ALT>>=
# produce scores for alternative anchoring model
@

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<FACINEQ_MAKE>>=
# make factor inequality graphs
@

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[pdftex,10pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amstext}% for resizing the symbol in math
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[babel]{csquotes}
\usepackage{booktabs}
\usepackage{tocloft}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{accents}
\usepackage{rotating}
\usepackage{pdflscape}  % for landscape page
\usepackage{lmodern}  %font
\usepackage{natbib}
\usepackage{array}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{tikz}
\usepackage{bm}
\usepackage{array}
\usepackage{multirow}
\usepackage[multiple]{footmisc}   % for multiple footnotes
\usepackage{textgreek}            % for greek letters in text
\usepackage{ragged2e}             % for table notes justification
\usepackage{setspace} % for spacing
\onehalfspacing

\setlength{\jot}{11pt} % increase vertical spacing in equations
\usepackage{txfonts}
\usepackage[T1]{fontenc}

% define new columns for tables
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\renewcommand{\arraystretch}{1.2}%

% appendices/numeration/references
\usepackage[nottoc,numbib]{tocbibind} 		% bibliography in TOC
\usepackage[toc,page]{appendix} %appendix
\newcommand{\tocless}[2]{\bgroup\let\addcontentsline=\nocontentsline#1{#2}\egroup} % for empty section
\numberwithin{equation}{section} %for section eq numeration
\usepackage{hyperref}                            % references
\AtBeginDocument{%
\renewcommand\sectionautorefname{Section}        % custom autoref names
\renewcommand\subsectionautorefname{Section}
}
\newcommand{\aref}[1]{\hyperref[#1]{Appendix~\ref{#1}}} % for appendix sections
\usepackage{cleveref}

%tikz
\usepackage{tikz}
\usetikzlibrary{shapes,intersections}
\usetikzlibrary{positioning,arrows, arrows.meta}

%lists
\usepackage[inline]{enumitem}
\setlist{noitemsep}
\setlist[enumerate]{labelsep=*, leftmargin=*}
\setlist[itemize]{labelsep=*, leftmargin=*}
\usepackage[textfont={small},labelfont={bf,small},justification=centering]{caption}     % to allow multiple lines in captions, and customize the look

% page setup (from Racine)
\setlength{\topmargin}{0cm}
\setlength{\textheight}{23cm}
\setlength{\oddsidemargin}{.0cm}
\setlength{\evensidemargin}{.0cm}
\setlength{\textwidth}{16.5cm}
\setlength{\footskip}{1.5cm}
\setlength{\footnotesep}{0.4cm}

% additional symbols
\newcommand{\me}{\mathrm{e}}
\newcommand{\veps}{\varepsilon}
\newcommand{\E}{\mathbb{E}}
\newcommand{\1}{\mathds{1}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Corr}{\mathrm{Corr}}
\newcommand{\vect}{\mathrm{vec}}
\newcommand{\vecht}{\mathrm{vech}}
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}
\def\chk{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;}

% additional commands
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\bnm}{\begin{enumerate}}
\newcommand{\enm}{\end{enumerate}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}

\usepackage{authblk}
\title{Inequality in non-cognitive skills: a cross-cohort comparison}
\author[1,2]{Orazio Attanasio}
\author[1,2]{Richard Blundell}
\author[1,2]{Gabriella Conti}
\author[1,2]{Giacomo Mason}
\affil[1]{\emph{Institute for Fiscal Studies}}
\affil[1]{\emph{UCL Department of Economics}}
%\institute{UCL and IFS}
\date{\today}

\begin{document}
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Measurement Invariance}

Meaningful comparison of latent constructs across different groups of individuals and/or measurement occasions (in our case, cohorts) requires that the available measures have the same relationship with the latent factors. This property is denominated measurement invariance \citep{Vandenberg2000,Putnick2016}. 

Measurement invariance (MI) is a \emph{formally testable} property. Two main frameworks have been used for assessing MI: item-response theory (IRT), or structural equation modeling (SEM). This paper focuses on the latter, as it is the most commonly employed.\footnote{For an introduction to MI in an IRT framework, see for example \cite{Tay2015}.} In general, MI analyses in a SEM framework are carried out by specifying and estimating factor models of different invariance levels, and comparing their relative fit. It starts with the estimation of a minimally restrictive model, where all measurement parameters are allowed to vary across groups -- net of the necessary normalisations -- and proceeds with progressively restricting sets of parameters to be equal across groups. If the fit of more restrictive models is comparable to the configural model, different levels of invariance can be established.

In accordance with the SEM approach, we set up a (confirmatory) item factor analysis (IFA) model to examine measurement invariance. In our application, we observe 11 categorical items ($X_1$-$X_{11}$). Our exploratory analysis above shows that the correlation structure of these measures can be captured by a two-dimensional latent construct (factor) $\bm{\theta}$ -- externalising and internalising socioemotional skills. We make the commonly adopted assumption of a dedicated (or congeneric) factor structure, where each measure is assumed to load on only one latent dimension \citep{Attanasio2017c,Heckman2013}.

To account for the ordered nature of the measures, we specify a threshold model \citep{Muthen1984}. Individual $j=1\dots N_c$ in group $c=\{A,B\}$ is assumed to have a latent continuous propensity $X^*_{ijc}$ for each item $i=1,\dots,I$. Thus, $X^*_{ijc}$ is the child's propensity to exhibit each of the behaviours described in \autoref{tab:comm}, as reported by the mother. This propensity is modelled as a function of item- and group-specific intercepts $\nu_{ic}$ and loadings $\bm{\lambda}_{ic}$, and the individual's level on the latent construct vector $\bm{\theta}_{jc}$, plus an independent error component $u_{ijc}$. In our application, the latent factor is bidimensional, and corresponds to the externalising ($\theta_{jc}^{EXT}$) and internalising ($\theta_{jc}^{INT}$) skills.

The propensity for each item can be written as follows:\footnote{The dedicated factor structure is ensured by the sparsity of the loading matrix, i.e.: $$\bm{\Lambda}_{c} \coloneqq \begin{bmatrix} \lambda_{1c}, \dots, \lambda_{6c} & \bm{0} \\ \bm{0} & \lambda_{7c}, \dots, \lambda_{11c} \end{bmatrix}.$$}
\be\label{eq:propens}
X^*_{ijc} =\nu_{ic} + \bm{\lambda}_{ic}\bm{\theta}_{jc} + u_{ijc} \qquad \text{for} \quad i = 1,\dots,11 \\
\ee

or more compactly:
$$\bm{X}^*_{jc} =\bm{\nu}_c + \bm{\Lambda}_{c}\bm{\theta}_{jc} + \bm{u}_{jc}$$

Additional standard distributional assumptions are placed on the latent constructs and error terms:
$$\bm{\theta}_{jc} \sim N(\bm{\kappa}_c, \bm{\Phi}_c) \qquad \text{and} \qquad \bm{u}_{jc} \sim N(\bm{0}, \bm{\Psi}_c)$$

The model implies the following expression for the mean and covariance structure of the latent propensities:
$$\bm{\mu}_c=\bm{\nu}_c + \bm{\Lambda}_c\bm{\kappa}_c \qquad \text{and} \qquad \Sigma_c = \bm{\Lambda}_c \bm{\Phi}_c \bm{\Lambda}_c^\prime + \bm{\Psi}_c.$$

Finally, discreteness in the observed measures $X_{cji}$ is incorporated by introducing item- and group-specific threshold parameters $\tau_{ic}$. The observed measures as a function of the propensities $X^*$ can be then written as follows:
$$X_{ijc} = s \qquad \text{if} \; \tau_{s,ic} \leq X^*_{ijc} < \tau_{s+1,ic} \qquad \text{for} \; s=0,1,2$$
with $\tau_{0,ic}=-\infty$ and $\tau_{3,ic}=+\infty$.

% FOOTNOTE\footnote{As a consequence of the normality assumption on the error terms $\veps$, the probability that individual $j$ in group $c$ exhibits item $i$ with ``intensity" $s$ is:
% \begin{align*}
% \Pr(X_{ijc}=0) &= 1- \Phi(-\tau_{1,ic} + \nu_{ic} + \lambda_{ic}\bm{\theta}_{jc}) \\
% \Pr(X_{ijc}=1) &= \Phi(-\tau_{1,ic} + \nu_{ic} + \lambda_{ic}\bm{\theta}_{jc})
% \end{align*}
% for binary items and
% \begin{align*}
% \Pr(X_{ijc}=0) &= 1- \Phi(-\tau_{1,ic} + \nu_{ic} + \lambda_{ic}\bm{\theta}_{jc}) \\
% \Pr(X_{ijc}=1) &= \Phi(-\tau_{1,ic} + \nu_{ic} + \lambda_{ic}\bm{\theta}_{jc}) - \Phi(-\tau_{2,ic} + \nu_{ic} + \lambda_{ic}\bm{\theta}_{jc})\\
% \Pr(X_{ijc}=2) &= \Phi(-\tau_{2,ic} +  \nu_{ic} + \lambda_{ic}\bm{\theta}_{jc})
% \end{align*}
% for ordinal items. This IFA model can also be written as a 2-parameter Logit IRT model with item difficulty $b$ and item discrimination $a$. In the simplest case for a binary item $1$:
% $$\text{Probit}(X_{1jc}=1) = a_{1c}(\bm{\theta}_{jc} - b_{1c})$$
% such that $\tau_{1c}=a_{1c}b_{1c}$ and $a_{1c}=\lambda_{1c}$.}

% Binary items take values:
% \begin{equation}
% X_{cji}=
% \begin{cases}
% \qquad 0 \qquad \text{if} \; X^*_{cji}<\tau_{1,ci} \\
% \qquad 1 \qquad \text{if} \; X^*_{cji}\geq\tau_{1,ci}
% \end{cases}
% \end{equation}
% 
% An ordinal item takes values:
% 
% \begin{equation}
% X_{cji}=
% \begin{cases}
% \qquad 0 \qquad \text{if} \; X^*_{cji}<\tau_{1,ci} \\
% \qquad 1 \qquad \text{if} \; \tau_{1,ci} \leq X^*_{cji}<\tau_{2,ci} \\
% \qquad 2 \qquad \text{if} \; X^*_{cji}\geq\tau_{2,ci}
% \end{cases}
% \end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The model specification above cannot identify the parameters unless additional normalisations are imposed. A configural model is defined as a minimal set of restrictions that ensure identification of parameters across groups. There are infinite, equivalent ways in which the configural model can be parameterised -- the well-known issue of factor indeterminacy. Widely used parameterisations for the configural model are:
\bi[label=$\diamond$]
\item \underline{Delta parameterisation} {[WE{\textDelta}]} \citep{Wu2016a}

For all groups: $$\text{diag}(\bm{\Phi}) = \bm{I}, \quad \bm{\kappa}=\bm{0}, \quad \bm{\nu}=\bm{0}, \quad \text{and} \; \text{diag}(\bm{\Sigma})=\bm{I}.$$

\item \underline{Theta parameterisation} {[WE{\textTheta}]} \citep{Wu2016a}

For all groups: $$\text{diag}(\bm{\Phi}) = \bm{I}, \quad \bm{\kappa}=\bm{0}, \quad \bm{\nu}=\bm{0}, \quad \text{and} \; \text{diag}(\bm{\Psi})=\bm{I}.$$

\item \underline{Anchored parameterisation} {[MT]} \citep{Millsap2004}
  \bi
  \item For all groups, normalise a reference loading to 1 for each factor
  \item Set invariant across groups one threshold per item (e.g. $\tau_{0,Ai} = \tau_{0,Bi}$), and an additional threshold in the reference items above
  \item In the first group: $\bm{\kappa_A}=\bm{0}$, $\text{diag}(\bm{\Sigma}_A)=\bm{I}$
  \item Set all intercepts $\bm{\nu}$ to zero
  \ei
\ei
The first two parameterisations (WE{\textDelta} and WE{\textTheta}) normalise the mean and variance of factors to the same constants in both groups, and they leave all loadings and intercepts to be freely estimated; they only differ in whether the additional required normalisation is imposed on the variances of the error terms ($\bm{\Psi}$) or on the diagonal of the covariance matrix of the measures ($\bm{\Sigma}$). The MT parameterisation instead proceeds by identifying parameters in one group first, and then imposing cross-group equality constraints to identify parameters in other groups \citep{Wu2016a}.

Once the configural model has been estimated, measurement invariance analysis proceeds by estimating nested models that place increasing restrictions on the item parameters, by constraining them to be equal across groups $c$. In the case where available measures are continuous, MI analysis is straightforward \citep{vandeSchoot2012}: one set of parameters is restricted at a time, and the fit of the resulting models are compared to the configural model. The hierarchy of the nested models usually proceeds by testing loadings first, and then intercepts (to establish \emph{metric} and \emph{scalar} invariance -- see \citealp{Vandenberg2000}).

Invariance of systems with categorical measures is less well understood. In particular, the lack of explicit location and scale in the measures introduces an additional set of parameters (thresholds $\tau$) and makes identification reliant on more stringent normalisations. The first comprehensive approach for categorical measures is proposed by \cite{Millsap2004}. New identification results in \cite{Wu2016a} indicate that, in the categorical case, invariance properties cannot be examined by simply restricting one set of parameters at a time. This is because the identification conditions used in the configural baseline model, while being minimally restrictive on their own, become binding once certain additional restrictions are imposed. In light of this, they propose models that identify structures of different invariance levels. They find that some restrictions cannot be tested alone against the configural model, because the models they generate are statistically equivalent. This is true of loading invariance, and also of threshold invariance in the case when the number of categories of each ordinal item is 3 or less. Furthermore, they suggest that comparison of both latent means and variances requires invariance in loadings, thresholds, and intercepts.

{\color{red} ADD SOME MORE COMMENTS ON IDENTIFICATION HERE, to make everything more palatable to economics audience.}

We estimate the sequence of models detailed in \autoref{tab:invparam} by Weighted Least Squares.\footnote{Parameters are estimated by mean- and variance-adjusted weighted least squares (WLSMV) (see \citealp{Muthen2017a}); estimation starts from the items' polychoric correlation matrix, uses diagonally weighted least squares (DWLS), and exploits the full weight matrix to compute robust standard errors and test statistics. Robust WLS has proved in simulation studies to be moderately robust to small violations of the normality assumption in the latent underlying measures \citep{Flora2004}, and generally outperforms maximum likelihood in large samples \citep{Beauducel2006,Li2016}. All estimates are computed using the \texttt{lavaan} package in \textbf{\textsf{R}} \citep{Rosseel2012}.}
For the purposes of the analysis, we define groups $c$ as cohort-gender cells, with the reference group being males in the BCS (1970) cohort. We then compare the fit of each model against the configural model (i.e. the least restrictive). According to recommended practice, we diplay a range of fit indices. Comparison of $\chi^2$ values across models is the most common strategy. However, tests based on $\Delta \chi^2$ are known to display increasing Type I error rates with sample size and model complexity \citep{Sass2014a}. The use of approximate fit indices (AFIs) has been proposed alongside $\chi^2$ to overcome these limitation. These indices do not have a known sampling distribution, thus making it necessary to rely on rules of thumb to assess what level of \textDelta AFI indicates invariance. Nevertheless, AFIs provide valuable corrections for model parsimony.\footnote{Commonly adopted AFIs in studies of measurement invariance are the root mean squared error of approximation (RMSEA) and the Tucker-Lewis index (TLI). Simulation evidence by \cite{Cheung2002} shows that these indices can show correlation between overall and relative fit, and suggest relying on additional indices, such as the comparative fit index (CFI, \citealp{Bentler1990}), McDonald non-centrality index (MFI, \citealp{McDonald1989}), and Gamma-hat index \citep{Steiger1989} for the case of ordered measures. Commonly accepted thresholds for rejection are $\Delta CFI < - 0.01$, $\Delta MFI < - 0.02$, and $\Delta Gamma hat < - 0.001$. \cite{Meade2008}, using the results from a simulation study, suggests stricter thresholds that should apply in a variety of conditions. For CFI, a single cutoff value of $.002$ is proposed, while cutoffs for MFI depend on the problem's characteristics; in our case (2 factors, 11 items), they suggest $.0066$. \cite{Sass2014a} however cast some doubts of the generalisability of these cutoffs to WLSMV estimators.}

{\color{red} Motivation for choosing RMSEA (does not seem supported in literature, see above).}

The fit of each estimated model using our full sample is compared in Panel A of \autoref{tab:fit}.\footnote{We do not present fit results for the threshold invariance model, as it is statistically equivalent to the configural model and thus its fit is mathematically the same.} The overall fit of the configural model is satisfactory according to widely accepted rules of thumb, with RMSEA close to $0.05$ and CFI close to $.95$ \citep{Hu1999}. For all invariance levels, a chi-squared difference would point to a lack of measurement invariance. However, as detailed above, this test is expected to lead to substantial Type I error with a relatively large sample size such as ours. For the model with restricted thresholds and loadings, most of the \textDelta AFIs indicate that this level of invariance is justified in our data. However, further restricting intercepts results in a model where invariance is rejected across the board.

\begin{table}[]
\centering\setstretch{1.2} \footnotesize
\caption{Parameterisations for measurement invariance}\label{tab:invparam}
\begin{tabular}{L{.18\textwidth}L{.45\textwidth}L{.3\textwidth}}
\toprule
\textbf{Invariance level}     & \textbf{Description} & \textbf{Restrictions} \\ \midrule \\
Configural (WE{\textTheta})   
    & \bi[label=$\cdot$] \item Minimally restrictive model for identification \ei
    & For all groups: $\begin{array}{|l} \text{diag}(\bm{\Phi}) = \bm{I} \\
                      \bm{\kappa}=\bm{0} \\
                      \bm{\nu}=\bm{0} \\
                      \text{diag}(\bm{\Psi})=\bm{I} \end{array}$
                      \\ \\
Threshold invariance
    & \bi[label=$\cdot$] \item Restricts thresholds $\tau$ to be equal across groups
                  \item Statistically equivalent to configural (when measures have 3 categories or less)\ei
    & $\tau_{1,ci} = \tau_{1,c^\prime i}$ for all items, $\forall c, c^\prime$
                      \newline $\tau_{2,ci} = \tau_{2,c^\prime i}$ for non-binary items, $\forall c, c^\prime$
                      \newline For all groups: $\begin{array}{|l} \text{diag}(\bm{\Phi}) = \bm{I} \\ 
                                                \bm{\kappa}=\bm{0} \end{array}$
                      \newline For ref. group $A$: $\;\begin{array}{|l} \bm{\nu}_A=\bm{0} \\
                                                  \text{diag}(\bm{\Sigma}_A)=\bm{I} \end{array}$
                   \\ \\
Threshold and Loading invariance
    & \bi[label=$\cdot$] \item Restricts thresholds $\tau$ and loadings $\lambda$ to be equal across groups
                  \item Allows comparison of latent factor variances \ei
    & $\tau_{1,ci} = \tau_{1,c^\prime i}$ for all items, $\forall c, c^\prime$
                      \newline $\tau_{2,ci} = \tau_{2,c^\prime i}$ for non-binary items, $\forall c, c^\prime$
                      \newline $\lambda_{ci} = \lambda_{c^\prime i}$ for all items, $\forall c, c^\prime$
                      \newline For all groups: $\bm{\kappa}=\bm{0}$
                      \newline For ref. group $A$: $\;\begin{array}{|l} \bm{\nu}_A=\bm{0} \\
                                                  \text{diag}(\bm{\Sigma}_A)=\bm{I} \\
                                                  \text{diag}(\bm{\Phi}_A) = \bm{I} \end{array}$ 
                   \\ \\
Threshold, Loading, and Intercept invariance
    & \bi[label=$\cdot$] \item Restricts thresholds $\tau$ and loadings $\lambda$ to be equal across groups
                  \item Restricts intercepts $\nu$ to zero in both groups
                  \item Allows comparison of latent factor variances \emph{and} means \ei
    & $\tau_{1,ci} = \tau_{1,c^\prime i}$ for all items, $\forall c, c^\prime$
                      \newline $\tau_{2,ci} = \tau_{2,c^\prime i}$ for non-binary items, $\forall c, c^\prime$
                      \newline $\lambda_{ci} = \lambda_{c^\prime i}$ for all items, $\forall c, c^\prime$
                      \newline For all groups: $\bm{\nu}=\bm{0}$
                      \newline For ref. group $A$: $\;\begin{array}{|l} \bm{\kappa}_A=\bm{0} \\
                                                  \text{diag}(\bm{\Sigma}_A)=\bm{I} \\
                                                  \text{diag}(\bm{\Phi}_A) = \bm{I} \end{array}$ 
\\ \\ \bottomrule
\end{tabular}
\end{table}

% ADD PARTIAL INVARIANCE


\clearpage
\bibliographystyle{chicago}
\bibliography{/Users/giacomomason/Dropbox/Zotero/cohorts.bib}


\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\begin{landscape}
\begin{table}[]
\caption{Item wording and prevalence, by cohort -- females}\label{tab:meantab_f}
\centering\setstretch{1.2} \footnotesize
<<MEANTAB_F, dependson="MEANTABLE", results='asis'>>=
require(xtable)
table <- meantab[[2]] # females
table <- table[,!names(table) %in% c("bcs.num", "mcs.num")] # drop if unneeded
printmeantab(table)
@
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[]
\caption{Item wording and prevalence, by cohort -- males}\label{tab:meantab_m}
\centering\setstretch{1.2} \footnotesize
<<MEANTAB_M, dependson="MEANTABLE", results='asis'>>=
require(xtable)
table <- meantab[[1]] # males
table <- table[,!names(table) %in% c("bcs.num", "mcs.num")] # drop if unneeded
printmeantab(table)
@
\end{table}
\end{landscape}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{landscape}
\begin{table}[ht]
\caption{Measurement invariance fit comparison}\label{tab:fit}
\centering\setstretch{1.2} \footnotesize
<<FA_FIT_RES, dependson="FA_FIT", results='asis'>>=
require(xtable)

table <- rbind(fit_main,fit_agesub)

print(xtable(table,
                    align="L{0cm}L{.20\\textwidth}C{.05\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}C{.08\\textwidth}",
                    digits = 4
                    ),
             size="\\small",
             include.rownames=F,
             include.colnames=F,
             booktabs = T,
             add.to.row = list(pos = c(list(0,4)),
                              command = c(
                              # header
            "& & \\multicolumn{6}{c}{\\textbf{Absolute fit}} & \\multicolumn{6}{c}{\\textbf{Relative fit}} 
                  \\\\ \\cmidrule(lr){3-8} \\cmidrule(lr){9-14}
            Model & Num. params & $\\chi^2$ & RMSEA & SRMR & MFI & CFI & G-hat & $\\chi^2$ $p$ & \\textDelta RMSEA & \\textDelta SRMR &  \\textDelta MFI & \\textDelta CFI & \\textDelta G-hat \\\\ 
& (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) & (10) & (11) & (12) & (13) \\\\ \\midrule
                       \\textbf{A: All ages} \\\\",
                      "\\newline \\textbf{B: 59-61 months sample} \\\\ \\midrule "
                                    )),
             sanitize.text.function = function(x){x},
             sanitize.rownames.function = function(x){""}, # to not print row numbers
             tabular.environment = "tabular", width = "\\textwidth",
             floating = FALSE
)

@
\justify {\scriptsize \emph{Notes}: The table presents fit indices for models of different invariance levels, following \cite{Wu2016a} Col. (1) displays the number of estimated parameters for each model. Col. (2) and (8) present the value of the $\chi^2$ statistic and the pvalue of the test of equality with respect to the configural model. Col. (3)-(7) and (9)-(13) present alternative fit indices (AFIs), in absolute values and differences from the configural model respectively. RMSEA = Root mean squared error of approximation; SRMR = standardised root mean residual; MFI = McDonald non-centrality index; CFI = comparative fit index; G-hat = gamma-hat. Panel A shows results for the whole sample of children in the BCS and MCS cohorts. Panel B is restricted to a subsample of children in the age range of maximum overlap between the two cohorts (59-61 months).
\par}
\end{table}
\end{landscape}

\clearpage
\begin{table}
\caption{Estimated parameters -- Threshold and loading invariance model (anchored)}\label{tab:measpars}
\centering\setstretch{1.2}\scriptsize
<<RES_FA_PAR, dependson="FA_FIT", results='asis'>>=

table <- getmeaspars(fa.tlmt[[1]], groups = 4, mode = "tl")

# sequences to add rows
rws <- seq(2, (nrow(table)-1), by = 1) # start from row 2 (exclude model titles)
rwsl <- as.list(rws)

print.xtable(xtable(table,
              align="C{0cm}C{.06\\textwidth}C{.04\\textwidth}C{.07\\textwidth}C{.057\\textwidth}C{.057\\textwidth}C{.057\\textwidth}C{.057\\textwidth}C{.057\\textwidth}C{.057\\textwidth}C{.057\\textwidth}C{.057\\textwidth}",
              digits = 3
                    ),
             include.rownames=F,
             include.colnames=F,
             booktabs = T,
             add.to.row = list(pos = c(list(0)),
                              command = c(
                              # header
                                          " &
                                            & \\textbf{Loadings}
                                            & \\multicolumn{2}{c}{\\textbf{Thresholds}}
                                            & \\multicolumn{3}{c}{\\textbf{Intercepts}}
                                            & \\multicolumn{3}{c}{\\textbf{Variances}}
                                            \\\\ \\cmidrule(lr){3-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-8} \\cmidrule(lr){9-11}

                                            &
                                            & $\\lambda$
                                            & $\\tau_1$ & $\\tau_2$
                                            & \\multicolumn{3}{c}{$\\nu$}
                                            & \\multicolumn{3}{c}{$\\text{diag}(\\Psi)$} \\\\

                                            Measure
                                            & Factor
                                            & All
                                            & All & All
                                            & BCS F & MCS M & MCS F
                                            & BCS F & MCS M & MCS F
                                            \\\\ "
                      )),
             sanitize.text.function = function(x){x},
             sanitize.rownames.function = function(x){""}, # to not print row numbers
             tabular.environment = "tabular", width = "\\textwidth",
             floating = FALSE
)
@
\end{table}

\begin{table}
\caption{Estimated latent variable parameters -- Threshold and loading invariance model (anchored)}\label{tab:lvpars}
\centering\setstretch{1.2}\scriptsize
<<RES_FA_LV, dependson="FA_FIT", results='asis'>>=
require(xtable)

lvtab <- getlvpars(fa.tlmt[[1]], groups = 4)
table <- rbind(lvtab$Males,lvtab$Females)


print.xtable(xtable(table,
                     align="C{0cm}L{.13\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}C{.06\\textwidth}",
                    digits = 3
                    ),
             include.rownames=F,
             include.colnames=F,
             booktabs = T,
             add.to.row = list(pos = c(list(0,2,4)),
                              command = c(
                              # header
                      "\\toprule
                      & \\multicolumn{4}{c}{\\textbf{BCS}}
                      & \\multicolumn{4}{c}{\\textbf{MCS}} \\\\ \\cmidrule(lr){2-5} \\cmidrule(lr){6-9}

                      & Mean
                      & \\multicolumn{2}{c}{Covariance}
                      & \\multicolumn{1}{c}{Correlation}
                      & Mean
                      & \\multicolumn{2}{c}{Covariance}
                      & \\multicolumn{1}{c}{Correlation} \\\\

                      \\textbf{Males} \\\\",
                      "\\textbf{Females} \\\\",
                      "\\bottomrule"
                                    )),
             hline.after = NULL,  # remove default booktabs lines
             sanitize.text.function = function(x){x},
             sanitize.rownames.function = function(x){""}, # to not print row numbers
             tabular.environment = "tabular", width = "\\textwidth",
             floating = FALSE
)

@
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage

<<FA_FIT_PART, dependson="FA_INV_PART", results='markup'>>=
head(partialfit[order(partialfit$rmsea),], 15)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}
<<FACDENS, dependson="FA_SCORES_BIND", dev='tikz', fig.height=10, fig.width=10, out.width='\\linewidth'>>=
@
\caption{Scores}
\justify {\scriptsize \emph{Notes}: Density of scores from partial invariance model with constrained intercepts on items 1, 6, 9, 10.
\par}
\end{figure}

\begin{figure}
<<FACDENS_ALT, dependson="FA_SCORES_BIND", dev='tikz', fig.height=10, fig.width=10, out.width='\\linewidth'>>=
# graph x axis boundaries
maxx <- max(scores2plot_alt[names(scores2plot_alt) %in% c("EXT","INT")]) +.05
minx <- min(scores2plot_alt[names(scores2plot_alt) %in% c("EXT","INT")]) -.05

# common options
addopts.dens <- function(x) {
  x <- x +
    theme(
      axis.title.y=element_blank(),
      legend.position="none"
    ) +
    scale_x_continuous(name = "Score", breaks = seq(-3.5,1.5,.5)) +
    coord_cartesian(xlim = c(minx, maxx), ylim = c(0,.62)) +
    scale_fill_discrete("") + # remove fill guide title
    scale_colour_discrete(guide=FALSE) +  # remove colour legend
    geom_density(alpha = 0.1, bw = "nrd", adjust=1.5, kernel = "epanechnikov")
  return(x)
}

# densities of factor scores
pdext.ebm.m <- ggplot(subset(scores2plot_alt, sex=="M"), aes(x=EXT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("EXT Scores (Males)")
pdint.ebm.m <- ggplot(subset(scores2plot_alt, sex=="M"), aes(x=INT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("INT Scores (Males)")
pdext.ebm.f <- ggplot(subset(scores2plot_alt, sex=="F"), aes(x=EXT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("EXT Scores (Females)")
pdint.ebm.f <- ggplot(subset(scores2plot_alt, sex=="F"), aes(x=INT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("INT Scores (Females)")
denslist <- list(pdext.ebm.m, pdint.ebm.m, pdext.ebm.f, pdint.ebm.f) 
denslist <- lapply(denslist, addopts.dens) # apply options to all graphs
pcol <- plot_grid( denslist[[1]], denslist[[3]], denslist[[2]], denslist[[4]],
                   align = 'vh',
                   hjust = -1,
                   nrow = 2
)
# add legend
legend_b <- get_legend(denslist[[1]] + theme(legend.position="bottom"))
p <- plot_grid( pcol, legend_b, ncol = 1, rel_heights = c(1, .1))
p


@
\caption{Scores -- alternative restrictions}
\justify {\scriptsize \emph{Notes}: Density of scores from partial invariance model with constrained intercepts on items 3, 6, 8, 11.
\par}
\end{figure}

\begin{figure}
<<FACDENS_ALT2, dependson="FA_SCORES_BIND", dev='tikz', fig.height=10, fig.width=10, out.width='\\linewidth'>>=
# graph x axis boundaries
maxx <- max(scores2plot_alt2[names(scores2plot_alt2) %in% c("EXT","INT")]) +.05
minx <- min(scores2plot_alt2[names(scores2plot_alt2) %in% c("EXT","INT")]) -.05

# common options
addopts.dens <- function(x) {
  x <- x +
    theme(
      axis.title.y=element_blank(),
      legend.position="none"
    ) +
    scale_x_continuous(name = "Score", breaks = seq(-3.5,1.5,.5)) +
    coord_cartesian(xlim = c(minx, maxx), ylim = c(0,.62)) +
    scale_fill_discrete("") + # remove fill guide title
    scale_colour_discrete(guide=FALSE) +  # remove colour legend
    geom_density(alpha = 0.1, bw = "nrd", adjust=1.5, kernel = "epanechnikov")
  return(x)
}

# densities of factor scores
pdext.ebm.m <- ggplot(subset(scores2plot_alt2, sex=="M"), aes(x=EXT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("EXT Scores (Males)")
pdint.ebm.m <- ggplot(subset(scores2plot_alt2, sex=="M"), aes(x=INT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("INT Scores (Males)")
pdext.ebm.f <- ggplot(subset(scores2plot_alt2, sex=="F"), aes(x=EXT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("EXT Scores (Females)")
pdint.ebm.f <- ggplot(subset(scores2plot_alt2, sex=="F"), aes(x=INT, group=cohort, fill=cohort, colour=cohort)) + ggtitle("INT Scores (Females)")
denslist <- list(pdext.ebm.m, pdint.ebm.m, pdext.ebm.f, pdint.ebm.f) 
denslist <- lapply(denslist, addopts.dens) # apply options to all graphs
pcol <- plot_grid( denslist[[1]], denslist[[3]], denslist[[2]], denslist[[4]],
                   align = 'vh',
                   hjust = -1,
                   nrow = 2
)
# add legend
legend_b <- get_legend(denslist[[1]] + theme(legend.position="bottom"))
p <- plot_grid( pcol, legend_b, ncol = 1, rel_heights = c(1, .1))
p


@
\caption{Scores -- alternative restrictions}
\justify {\scriptsize \emph{Notes}: Density of scores from partial invariance model with constrained intercepts on items 3, 6, 9, 10.
\par}
\end{figure}


\begin{figure}
<<FACINEQ_FSC, dependson="FA_SCORES_BIND", dev='tikz', fig.height=9, fig.width=10, out.width='\\linewidth'>>=
# plot
fi <- fi_fsc # select result
gridExtra::grid.arrange(fi$ineqlist[[1]],fi$ineqlist[[2]],
                        fi$ineqlist[[3]],fi$ineqlist[[4]],
                        fi$histlist[[1]],fi$histlist[[2]], fi$legend,
                        ncol=2, nrow=4, heights = c(4,4,2,0.5))
@
\caption{Inequality by father occupation -- normalised}
\end{figure}

\begin{figure}
<<FACINEQ_FSC2, dependson="FA_SCORES_BIND", dev='tikz', fig.height=9, fig.width=10, out.width='\\linewidth'>>=
# plot
fi <- fi_fsc2 # select result
gridExtra::grid.arrange(fi$ineqlist[[1]],fi$ineqlist[[2]],
                        fi$ineqlist[[3]],fi$ineqlist[[4]],
                        fi$histlist[[1]],fi$histlist[[2]], fi$legend,
                        ncol=2, nrow=4, heights = c(4,4,2,0.5))
@
\caption{Inequality by father occupation -- not normalised}
\end{figure}

\begin{figure}
<<FACINEQ_FSC3, dependson="FA_SCORES_BIND", dev='tikz', fig.height=9, fig.width=10, out.width='\\linewidth'>>=
fi_fsc3 <- plotineq(scores2plot_alt, "fscl5wb", ylab = "Score ", xlab = "Father Occupation (5)",
                   ylim = c(-.8,1.0))
fi <- fi_fsc3 # select result
gridExtra::grid.arrange(fi$ineqlist[[1]],fi$ineqlist[[2]],
                        fi$ineqlist[[3]],fi$ineqlist[[4]],
                        fi$histlist[[1]],fi$histlist[[2]], fi$legend,
                        ncol=2, nrow=4, heights = c(4,4,2,0.5))
@
\caption{Inequality by father occupation -- not normalised, alternative restrictions}
\end{figure}

\begin{figure}
<<FACINEQ_PS, dependson="FA_SCORES_BIND", dev='tikz', fig.height=9, fig.width=10, out.width='\\linewidth'>>=
# plot
fi <- fi_ps # select result
gridExtra::grid.arrange(fi$ineqlist[[1]],fi$ineqlist[[2]],
                        fi$ineqlist[[3]],fi$ineqlist[[4]],
                        fi$histlist[[1]],fi$histlist[[2]], fi$legend,
                        ncol=2, nrow=4, heights = c(4,4,2,0.5))
@
\caption{Inequality by mother education -- normalised}
\end{figure}

\begin{figure}
<<FACINEQ_PS2, dependson="FA_SCORES_BIND", dev='tikz', fig.height=9, fig.width=10, out.width='\\linewidth'>>=
# plot
fi <- fi_ps2 # select result
gridExtra::grid.arrange(fi$ineqlist[[1]],fi$ineqlist[[2]],
                        fi$ineqlist[[3]],fi$ineqlist[[4]],
                        fi$histlist[[1]],fi$histlist[[2]], fi$legend,
                        ncol=2, nrow=4, heights = c(4,4,2,0.5))
@
\caption{Inequality by mother education -- not normalised}
\end{figure}

\end{document}